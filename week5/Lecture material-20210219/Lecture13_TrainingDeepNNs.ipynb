{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " # Lecture 13: Training deep neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](https://www.tensorflow.org/images/colab_logo_32px.png)\n",
    "[Run in colab](https://colab.research.google.com/drive/1ftihrW-_2cIzCkA3TYScFgoOe1bQwTrT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last executed: 2021-02-21 10:01:53\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "print(\"Last executed: \" + now.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "def reset_state(seed=42):\n",
    "    tf.keras.backend.clear_session()\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Vanishing and exploding gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training typically relies on gradients.\n",
    "\n",
    "*Vanishing gradients problem*: For deep networks, gradients in lower layers can become very small.  Hence, corresponding weights are not updated during training.\n",
    "\n",
    "*Exploding gradients problem*: In some situations (typically recurrent neural networks) gradients can become very large.  Hence, weight updates are very large and the training algorithm may not converge.\n",
    "\n",
    "In general deep neural networks can suffer from *unstable gradients*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Problematic activation functions\n",
    "\n",
    "One common cause of vanishing gradients in the past was the use of the sigmoid activation function (and unit Gaussian initialisation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-5.0, 5.0, -0.2, 1.2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = np.linspace(-5, 5, 200)\n",
    " \n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [1, 1], 'k--')\n",
    "plt.plot([0, 0], [-0.2, 1.2], 'k-')\n",
    "plt.plot([-5, 5], [-3/4, 7/4], 'g--')\n",
    "plt.plot(z, logit(z), \"b-\", linewidth=2)\n",
    "props = dict(facecolor='black', shrink=0.1)\n",
    "plt.annotate('Saturating', xytext=(3.5, 0.7), xy=(5, 1), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.annotate('Saturating', xytext=(-3.5, 0.3), xy=(-5, 0), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.annotate('Linear', xytext=(2, 0.2), xy=(0, 0.5), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.grid(True)\n",
    "plt.title(\"Sigmoid activation function\", fontsize=14)\n",
    "plt.axis([-5, 5, -0.2, 1.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variance of outputs grows at each layer.  Final layers essentially saturate.  Gradients on final layers then very small and when propagate gradients back with back-propagation then get vanishing gradients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Weight initialisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid this problem need signals and gradents to *not* decay as propagating through network.\n",
    "\n",
    "Avoid decaying signals/gradients by promoting equal variance at outputs and inputs of layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Can be promoted by random initialisation of weights to follow Gaussian with standard deviation:\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\text{Sigmoid activation:} \\quad\\quad & \\sigma = \\sqrt{\\frac{2}{n_{\\rm inputs}+n_{\\rm outputs}}} \\\\\n",
    "\\text{Hyperbolic tangent activation:} \\quad\\quad & \\sigma = 4\\sqrt{\\frac{2}{n_{\\rm inputs}+n_{\\rm outputs}}} \\\\\n",
    "\\text{ReLU activation:} \\quad\\quad & \\sigma = \\sqrt{2}\\sqrt{\\frac{2}{n_{\\rm inputs}+n_{\\rm outputs}}} \\\\\n",
    "\\end{eqnarray}\n",
    "\n",
    "where $n_{\\rm inputs}$ and $n_{\\rm outputs}$ are the number of input and output nodes, respectively, for the layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of different weight initialisation strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Weight initialisation in TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Constant',\n",
       " 'GlorotNormal',\n",
       " 'GlorotUniform',\n",
       " 'HeNormal',\n",
       " 'HeUniform',\n",
       " 'Identity',\n",
       " 'Initializer',\n",
       " 'LecunNormal',\n",
       " 'LecunUniform',\n",
       " 'Ones',\n",
       " 'Orthogonal',\n",
       " 'RandomNormal',\n",
       " 'RandomUniform',\n",
       " 'TruncatedNormal',\n",
       " 'VarianceScaling',\n",
       " 'Zeros',\n",
       " 'constant',\n",
       " 'deserialize',\n",
       " 'get',\n",
       " 'glorot_normal',\n",
       " 'glorot_uniform',\n",
       " 'he_normal',\n",
       " 'he_uniform',\n",
       " 'identity',\n",
       " 'lecun_normal',\n",
       " 'lecun_uniform',\n",
       " 'ones',\n",
       " 'orthogonal',\n",
       " 'random_normal',\n",
       " 'random_uniform',\n",
       " 'serialize',\n",
       " 'truncated_normal',\n",
       " 'variance_scaling',\n",
       " 'zeros']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[name for name in dir(keras.initializers) if not name.startswith(\"_\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Can often simply set initialiser when defining layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x7f8e279a09a0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reset_state()\n",
    "\n",
    "keras.layers.Dense(10, activation=\"relu\", kernel_initializer=\"he_normal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or can set up a `VarianceScaling` object directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x7f8dd952f9d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "he_avg_init = keras.initializers.VarianceScaling(scale=2., mode='fan_avg', distribution='uniform')\n",
    "keras.layers.Dense(10, activation=\"sigmoid\", kernel_initializer=he_avg_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Non-saturating activation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ReLU activation behaves much better than the sigmoid in deep networks since it does not saturate for positive values (and it is fast to compute)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "However, the ReLU does suffer from the *dying neuron* problem.\n",
    "\n",
    "In this senario neurons effectively die and only output zero.  The neuron is unlikely to come back to life since the gradient of the ReLU activation function is zero for negative inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Leaky ReLU\n",
    "\n",
    "The *leaky ReLU* avoids this problem and is defined by\n",
    "\n",
    "$$\n",
    "\\text{LeakyReLU}_\\alpha(z) = \\max(\\alpha z, z),\n",
    "$$\n",
    "\n",
    "where the hyperparameter $\\alpha$ defines how much the leaky ReLU leaks (typically $\\alpha=0.01$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's plot the Leaky ReLU activation function for $\\alpha=0.05$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaky_relu(z, alpha=0.01):\n",
    "    return np.maximum(alpha*z, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-5.0, 5.0, -0.5, 4.2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = np.linspace(-5, 5, 200)\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(z, leaky_relu(z, 0.05), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([0, 0], [-0.5, 4.2], 'k-')\n",
    "plt.grid(True)\n",
    "props = dict(facecolor='black', shrink=0.1)\n",
    "plt.annotate('Leak', xytext=(-3.5, 0.5), xy=(-5, -0.2), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.title(\"Leaky ReLU activation function\", fontsize=14)\n",
    "plt.axis([-5, 5, -0.5, 4.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### ELU\n",
    "\n",
    "Another alternative is the *exponental linear unit* (ELU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elu(z, alpha=1):\n",
    "    return np.where(z < 0, alpha * (np.exp(z) - 1), z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the ELU activation function for $\\alpha=1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-5.0, 5.0, -2.2, 3.2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(z, elu(z), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [-1, -1], 'k--')\n",
    "plt.plot([0, 0], [-2.2, 3.2], 'k-')\n",
    "plt.grid(True)\n",
    "plt.title(r\"ELU activation function ($\\alpha=1$)\", fontsize=14)\n",
    "plt.axis([-5, 5, -2.2, 3.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Properties:\n",
    "- Non-zero gradient for $z<0$ to avoid dying neuron issue.\n",
    "- Smooth so gradients well defined.\n",
    "- But is slower to compute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Activations functions in TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow supports a lot of activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['deserialize',\n",
       " 'elu',\n",
       " 'exponential',\n",
       " 'gelu',\n",
       " 'get',\n",
       " 'hard_sigmoid',\n",
       " 'linear',\n",
       " 'relu',\n",
       " 'selu',\n",
       " 'serialize',\n",
       " 'sigmoid',\n",
       " 'softmax',\n",
       " 'softplus',\n",
       " 'softsign',\n",
       " 'swish',\n",
       " 'tanh']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m for m in dir(keras.activations) if not m.startswith(\"_\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Can again simply set when definiting layer or can construct directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x7f8dd8b6f9a0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reset_state()\n",
    "keras.layers.Dense(10, activation=\"elu\", name=\"hidden1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x7f8e24b4fb50>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reset_state()\n",
    "keras.layers.Dense(10, activation=keras.layers.Activation(\"elu\"), name=\"hidden1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Batch normalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While weight normalisation can reduce gradient problems at the beginning of training, it does not guarantee that these problems won't resurface during training.\n",
    "\n",
    "*Batch normalisation* adds normalisation during training to address these issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Consists of zero-centering and normalising inputs just before the activation function, followed by shifting and scaling the result.  The shift and scale are considered additional parameters that are learnt during training.\n",
    "\n",
    "This approach allows training to select the appropriate scale and shift (mean) for each layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The mean and standard deviation of the unnormalised inputs are computed for each mini-batch, hence the name *batch normalisation*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "When the trained network is applied to the test set there are no batches, so instead the entire *training* set's mean and standard deviation are used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Batch normalisation in TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 784)               3136      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 271,346\n",
      "Trainable params: 268,978\n",
      "Non-trainable params: 2,368\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "reset_state()\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "keras.layers.Flatten(input_shape=[28, 28]), keras.layers.BatchNormalization(),\n",
    "keras.layers.Dense(n_hidden1, activation=\"elu\", kernel_initializer=\"he_normal\"), keras.layers.BatchNormalization(),# add barch layer after dense layer\n",
    "keras.layers.Dense(n_hidden2, activation=\"elu\", kernel_initializer=\"he_normal\"), keras.layers.BatchNormalization(),# add barch layer\n",
    "keras.layers.Dense(n_outputs, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('batch_normalization/gamma:0', True),\n",
       " ('batch_normalization/beta:0', True),\n",
       " ('batch_normalization/moving_mean:0', False),\n",
       " ('batch_normalization/moving_variance:0', False)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(var.name, var.trainable) for var in model.layers[1].variables]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "exercise_pointer"
    ]
   },
   "source": [
    "**Exercises:** *You can now complete Exercise 1 in the exercises associated with this lecture.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pretraining and transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A deep network trained for one task can often be adapted for a similar task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Reuse lower layers of network trained for another task.\n",
    "\n",
    "<!-- <img src=\"https://raw.githubusercontent.com/astro-informatics/course_mlbd_images/master/Lecture13_Images/transfer_learning.png\" style=\"height: 350px;\"/> -->\n",
    "\n",
    "![](https://raw.githubusercontent.com/astro-informatics/course_mlbd_images/master/Lecture13_Images/transfer_learning.png)\n",
    "\n",
    "[Credit: Geron]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For transfer learning to be successful the data must have similar low-level features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Reusing a Keras model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's work through a transfer learning example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Split the fashion MNIST training set into two:\n",
    "* `X_train_A`: all images of all items, except sandals and shirts (classes 5 and 6).\n",
    "* `X_train_B`: first 200 images of sandals or shirts.\n",
    "\n",
    "The validation set and the test set are split similarly, but without restricting the number of images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Dataset B corresponds to a simple problem (binary classification) but we only have a small number of training instances. \n",
    "\n",
    "Dataset A corresponds to a more difficult problem (classification between 8 classes) but we have much more data.\n",
    "\n",
    "We will attempt to transfer knowledge from setting A to B, since classes in set A (sneakers, ankle boots, coats, t-shirts, etc.) are somewhat similar to classes in set B (sandals and shirts). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Aside: Note that only patterns that occur in the same location can be reused since we are using `Dense` layers (CNNs will be much more effective in tranferring information detected anywhere in the image due to their translational invariance properties, as we'll see in the CNN lecture)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Set up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "X_train_full = X_train_full / 255.0\n",
    "X_test = X_test / 255.0\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "\n",
    "def split_dataset(X, y):\n",
    "    y_5_or_6 = (y == 5) | (y == 6) # sandals or shirts\n",
    "    y_A = y[~y_5_or_6]\n",
    "    y_A[y_A > 6] -= 2 # class indices 7, 8, 9 should be moved to 5, 6, 7\n",
    "    y_B = (y[y_5_or_6] == 6).astype(np.float32) # binary classification task: is it a shirt (class 6)?\n",
    "    return ((X[~y_5_or_6], y_A),\n",
    "            (X[y_5_or_6], y_B))\n",
    "\n",
    "(X_train_A, y_train_A), (X_train_B, y_train_B) = split_dataset(X_train, y_train)\n",
    "(X_valid_A, y_valid_A), (X_valid_B, y_valid_B) = split_dataset(X_valid, y_valid)\n",
    "(X_test_A, y_test_A), (X_test_B, y_test_B) = split_dataset(X_test, y_test)\n",
    "X_train_B = X_train_B[:200]\n",
    "y_train_B = y_train_B[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((43986, 28, 28), (200, 28, 28))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_A.shape, X_train_B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0, 5, 7, 7, 7, 4, 4, 3, 4, 0, 1, 6, 3, 4, 3, 2, 6, 5, 3, 4, 5,\n",
       "       1, 3, 4, 2, 0, 6, 7, 1], dtype=uint8)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_A[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_B[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Define, compile, fit and save model on dataset A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_state()\n",
    "model_A = keras.models.Sequential()\n",
    "model_A.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "for n_hidden in (300, 100, 50, 50, 50):\n",
    "    model_A.add(keras.layers.Dense(n_hidden, activation=\"selu\"))\n",
    "model_A.add(keras.layers.Dense(8, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 784)               3136      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 271,346\n",
      "Trainable params: 268,978\n",
      "Non-trainable params: 2,368\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "model_A.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1375/1375 [==============================] - 4s 2ms/step - loss: 0.9248 - accuracy: 0.6994 - val_loss: 0.3890 - val_accuracy: 0.8677\n",
      "Epoch 2/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.3651 - accuracy: 0.8748 - val_loss: 0.3289 - val_accuracy: 0.8824\n",
      "Epoch 3/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.3182 - accuracy: 0.8897 - val_loss: 0.3013 - val_accuracy: 0.8991\n",
      "Epoch 4/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.3048 - accuracy: 0.8954 - val_loss: 0.2892 - val_accuracy: 0.9013\n",
      "Epoch 5/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2803 - accuracy: 0.9029 - val_loss: 0.2774 - val_accuracy: 0.9066\n",
      "Epoch 6/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2700 - accuracy: 0.9080 - val_loss: 0.2733 - val_accuracy: 0.9071\n",
      "Epoch 7/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2625 - accuracy: 0.9091 - val_loss: 0.2720 - val_accuracy: 0.9091\n",
      "Epoch 8/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2608 - accuracy: 0.9117 - val_loss: 0.2589 - val_accuracy: 0.9141\n",
      "Epoch 9/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2557 - accuracy: 0.9108 - val_loss: 0.2562 - val_accuracy: 0.9143\n",
      "Epoch 10/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2510 - accuracy: 0.9138 - val_loss: 0.2540 - val_accuracy: 0.9165\n",
      "Epoch 11/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2430 - accuracy: 0.9170 - val_loss: 0.2494 - val_accuracy: 0.9155\n",
      "Epoch 12/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2422 - accuracy: 0.9171 - val_loss: 0.2511 - val_accuracy: 0.9128\n",
      "Epoch 13/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2359 - accuracy: 0.9181 - val_loss: 0.2446 - val_accuracy: 0.9163\n",
      "Epoch 14/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2266 - accuracy: 0.9232 - val_loss: 0.2413 - val_accuracy: 0.9178\n",
      "Epoch 15/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2224 - accuracy: 0.9242 - val_loss: 0.2446 - val_accuracy: 0.9193\n",
      "Epoch 16/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2260 - accuracy: 0.9218 - val_loss: 0.2386 - val_accuracy: 0.9195\n",
      "Epoch 17/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2191 - accuracy: 0.9250 - val_loss: 0.2405 - val_accuracy: 0.9175\n",
      "Epoch 18/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2171 - accuracy: 0.9250 - val_loss: 0.2429 - val_accuracy: 0.9158\n",
      "Epoch 19/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2181 - accuracy: 0.9246 - val_loss: 0.2328 - val_accuracy: 0.9205\n",
      "Epoch 20/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2112 - accuracy: 0.9272 - val_loss: 0.2332 - val_accuracy: 0.9208\n"
     ]
    }
   ],
   "source": [
    "history = model_A.fit(X_train_A, y_train_A, epochs=20,\n",
    "                    validation_data=(X_valid_A, y_valid_A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We achieve an accuracy ~92%, which is reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A.save(\"my_model_A.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Repeat on dataset B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B = keras.models.Sequential()\n",
    "model_B.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "for n_hidden in (300, 100, 50, 50, 50):\n",
    "    model_B.add(keras.layers.Dense(n_hidden, activation=\"selu\"))\n",
    "model_B.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "7/7 [==============================] - 1s 38ms/step - loss: 1.0360 - accuracy: 0.4975 - val_loss: 0.6314 - val_accuracy: 0.6004\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.5883 - accuracy: 0.6971 - val_loss: 0.4784 - val_accuracy: 0.8529\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.4380 - accuracy: 0.8854 - val_loss: 0.4102 - val_accuracy: 0.8945\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.4021 - accuracy: 0.8712 - val_loss: 0.3647 - val_accuracy: 0.9178\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.3361 - accuracy: 0.9348 - val_loss: 0.3300 - val_accuracy: 0.9320\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.3113 - accuracy: 0.9233 - val_loss: 0.3019 - val_accuracy: 0.9402\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.2817 - accuracy: 0.9299 - val_loss: 0.2804 - val_accuracy: 0.9422\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.2632 - accuracy: 0.9379 - val_loss: 0.2606 - val_accuracy: 0.9473\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.2373 - accuracy: 0.9481 - val_loss: 0.2428 - val_accuracy: 0.9523\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.2229 - accuracy: 0.9657 - val_loss: 0.2281 - val_accuracy: 0.9544\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.2155 - accuracy: 0.9590 - val_loss: 0.2150 - val_accuracy: 0.9584\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.1834 - accuracy: 0.9738 - val_loss: 0.2036 - val_accuracy: 0.9584\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.1671 - accuracy: 0.9828 - val_loss: 0.1931 - val_accuracy: 0.9615\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.1527 - accuracy: 0.9915 - val_loss: 0.1838 - val_accuracy: 0.9635\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.1595 - accuracy: 0.9904 - val_loss: 0.1746 - val_accuracy: 0.9686\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.1473 - accuracy: 0.9937 - val_loss: 0.1674 - val_accuracy: 0.9686\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.1412 - accuracy: 0.9944 - val_loss: 0.1604 - val_accuracy: 0.9706\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.1242 - accuracy: 0.9931 - val_loss: 0.1539 - val_accuracy: 0.9706\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.1224 - accuracy: 0.9931 - val_loss: 0.1482 - val_accuracy: 0.9716\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.1096 - accuracy: 0.9912 - val_loss: 0.1431 - val_accuracy: 0.9716\n"
     ]
    }
   ],
   "source": [
    "history = model_B.fit(X_train_B, y_train_B, epochs=20,\n",
    "                      validation_data=(X_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We achieve an accuracy ~97% since this is an easier problem (binary classification).\n",
    "\n",
    "However, we could do better by transferring information from setting A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Freezing lower layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lower layers of the first network have already learnt low-level features for the first task, so they can be reused as they are. \n",
    "\n",
    "That is, we freeze their weights so that they are not altered during subsequent training of the new network.\n",
    "\n",
    "We will take all layers from model A and then add a final output layer for our binary classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A = keras.models.load_model(\"my_model_A.h5\")\n",
    "model_B_on_A = keras.models.Sequential(model_A.layers[:-1]) # Reuse all layers except output.\n",
    "model_B_on_A.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Note that `model_B_on_A` and `model_A` now share layers.  When you train on `model_B_on_A` that will also impact `model_A`.\n",
    "\n",
    "To avoid this you can clone a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's freeze all layers except the final dense output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\",\n",
    "                     optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "                     metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "7/7 [==============================] - 1s 36ms/step - loss: 0.6108 - accuracy: 0.6233 - val_loss: 0.5812 - val_accuracy: 0.6379\n",
      "Epoch 2/4\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.5506 - accuracy: 0.6619 - val_loss: 0.5439 - val_accuracy: 0.6826\n",
      "Epoch 3/4\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.4861 - accuracy: 0.7482 - val_loss: 0.5121 - val_accuracy: 0.7150\n",
      "Epoch 4/4\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4861 - accuracy: 0.7455 - val_loss: 0.4835 - val_accuracy: 0.7333\n"
     ]
    }
   ],
   "source": [
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=4,\n",
    "                           validation_data=(X_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even with just one trained layer and a few epochs, our model is starting to learn the new problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now let's unfreeze and lower layers and train the full model to fine-tune it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\",\n",
    "                     optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "                     metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "7/7 [==============================] - 1s 35ms/step - loss: 0.4349 - accuracy: 0.7774 - val_loss: 0.3452 - val_accuracy: 0.8641\n",
      "Epoch 2/16\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.2956 - accuracy: 0.9143 - val_loss: 0.2600 - val_accuracy: 0.9270\n",
      "Epoch 3/16\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.2030 - accuracy: 0.9777 - val_loss: 0.2111 - val_accuracy: 0.9554\n",
      "Epoch 4/16\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.1751 - accuracy: 0.9789 - val_loss: 0.1793 - val_accuracy: 0.9696\n",
      "Epoch 5/16\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.1348 - accuracy: 0.9809 - val_loss: 0.1564 - val_accuracy: 0.9757\n",
      "Epoch 6/16\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.1173 - accuracy: 0.9973 - val_loss: 0.1396 - val_accuracy: 0.9797\n",
      "Epoch 7/16\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.1140 - accuracy: 0.9931 - val_loss: 0.1268 - val_accuracy: 0.9838\n",
      "Epoch 8/16\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.1001 - accuracy: 0.9931 - val_loss: 0.1166 - val_accuracy: 0.9858\n",
      "Epoch 9/16\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0835 - accuracy: 1.0000 - val_loss: 0.1068 - val_accuracy: 0.9888\n",
      "Epoch 10/16\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0774 - accuracy: 1.0000 - val_loss: 0.1002 - val_accuracy: 0.9899\n",
      "Epoch 11/16\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0690 - accuracy: 1.0000 - val_loss: 0.0941 - val_accuracy: 0.9899\n",
      "Epoch 12/16\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0718 - accuracy: 1.0000 - val_loss: 0.0890 - val_accuracy: 0.9899\n",
      "Epoch 13/16\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0566 - accuracy: 1.0000 - val_loss: 0.0841 - val_accuracy: 0.9899\n",
      "Epoch 14/16\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0494 - accuracy: 1.0000 - val_loss: 0.0804 - val_accuracy: 0.9899\n",
      "Epoch 15/16\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0545 - accuracy: 1.0000 - val_loss: 0.0770 - val_accuracy: 0.9899\n",
      "Epoch 16/16\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0472 - accuracy: 1.0000 - val_loss: 0.0740 - val_accuracy: 0.9899\n"
     ]
    }
   ],
   "source": [
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=16,\n",
    "                           validation_data=(X_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1408 - accuracy: 0.9705\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.14084088802337646, 0.9704999923706055]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B.evaluate(X_test_B, y_test_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0682 - accuracy: 0.9930\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06821806728839874, 0.9929999709129333]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B_on_A.evaluate(X_test_B, y_test_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Model gardens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many trained Tensor Flow models are available at \n",
    "[https://github.com/tensorflow/models](https://github.com/tensorflow/models)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Improved optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although standard (stochastic) gradient descent is very effective it can still be slow for deep networks.\n",
    "\n",
    "There are a number of more advanced optimizers that provide improvements, e.g.:\n",
    "- Momentum optimization\n",
    "- Nesterov accelerated gradient\n",
    "- AdaGrad\n",
    "- RMSProp\n",
    "- Adam optimization\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Recall gradient descent, with cost function $J(\\theta)$ and gradients $\\nabla_\\theta J(\\theta)$, proceeds simply by updating the weights $\\theta$ by taking a step $\\eta$ (learning rate) in the direction of the gradient:\n",
    "\n",
    "$$\\theta \\leftarrow \\theta - \\eta \\nabla_\\theta J(\\theta)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Momentum optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Momentum optimization uses the gradients to modify a momentum vector and uses the momentum to update the weights:\n",
    "\n",
    "1. $m \\leftarrow \\beta m + \\eta \\nabla_\\theta J(\\theta)$\n",
    "2. $\\theta \\leftarrow \\theta - m$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Gradient is used as an acceleration rather than speed.  Can help to traverse plateaus and to avoid local minima.\n",
    "\n",
    "The additional hyperparameter $\\beta$ is introduced as a friction term to avoid the momentum growing too large (typically $\\beta \\sim 0.9$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Nesterov accelerated gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesterov accelerated gradient is a variant of momentum optimization where the gradient is computed further ahead in the direction of the momentum:\n",
    "\n",
    "1. $m \\leftarrow \\beta m + \\eta \\nabla_\\theta J(\\theta + \\beta m)$\n",
    "2. $\\theta \\leftarrow \\theta - m$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In general the momentum will be pointing toward the optimum and so Nesterov modification typically provides an improvement over standard momentum optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### AdaGrad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaGrad scales down the gradient vector along the steepest direction by incorporating a gradient squared term:\n",
    "\n",
    "1. $s \\leftarrow s + \\nabla_\\theta J(\\theta) \\otimes \\nabla_\\theta J(\\theta)$\n",
    "2. $\\theta \\leftarrow \\theta - \\eta \\nabla_\\theta J(\\theta) \\oslash \\sqrt{s+\\epsilon}$\n",
    "\n",
    "Note that $\\otimes$ and $\\oslash$ are elementwise multiplication and division, respectively.\n",
    "\n",
    "The parameter $\\epsilon$ is introduced for numerical stability (typically $\\epsilon\\sim 10^{-10}$).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Basically, AdaGrad correspondings to an *adaptive learning rate* where the learning rate is decayed faster for steep directions.\n",
    "\n",
    "Consequently, it requires much less tuning of the learning rate $\\eta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<!-- <img src=\"https://raw.githubusercontent.com/astro-informatics/course_mlbd_images/master/Lecture13_Images/ada_grad.png\" style=\"height: 500px;\"/> -->\n",
    "\n",
    "![](https://raw.githubusercontent.com/astro-informatics/course_mlbd_images/master/Lecture13_Images/ada_grad.png)\n",
    "\n",
    "[Credit: Geron]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### RMSProp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSProp extends AdaGrad by introducing an exponential decay in the accumulated squared gradient:\n",
    "\n",
    "1. $s \\leftarrow \\beta s + (1-\\beta) \\nabla_\\theta J(\\theta) \\otimes \\nabla_\\theta J(\\theta)$\n",
    "2. $\\theta \\leftarrow \\theta - \\eta \\nabla_\\theta J(\\theta) \\oslash \\sqrt{s+\\epsilon}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "(Typically $\\beta\\sim 0.9$.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Avoids the problem where AdaGrad slows down too fast and so doesn't converge to the global optimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Adam optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adam optimization combines momentum and RMSProp:\n",
    "\n",
    "1. $m \\leftarrow \\beta_1 m + (1-\\beta_1) \\nabla_\\theta J(\\theta)$\n",
    "2. $s \\leftarrow \\beta_2 s + (1-\\beta_2) \\nabla_\\theta J(\\theta)\\otimes\\nabla_\\theta J(\\theta)$\n",
    "3. $m \\leftarrow \\frac{m}{1-\\beta_1^{t}}$, where $t$ is the iteration number \n",
    "4. $s \\leftarrow \\frac{s}{1-\\beta_2^{t}}$, where $t$ is the iteration number\n",
    "5. $\\theta \\leftarrow \\theta - \\eta m \\oslash \\sqrt{s+\\epsilon}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Steps 3 and 4 are introduced to boost $m$ and $s$ at the beginnning of training (since they are initialed to 0 they can otherwise be low at the beginning).\n",
    "\n",
    "(Typically $\\beta_1 \\sim 0.9$, $\\beta_2 \\sim 0.999$.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep networks have many parameters (sometimes millions) and so are prone to overfitting.\n",
    "\n",
    "Regularization therefore becomes increasingly important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Early stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple regularization strategy is to end training early, e.g. when performance on validation set starts to degrade.\n",
    "\n",
    "Although early stopping works well, other regularisation techniques can lead to better performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### $\\ell_2$ and $\\ell_1$ regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Tikhonov* regularization adopts $\\ell_2$ regularising term (also called *Ridge regression*):\n",
    "\n",
    "\n",
    "$$ R(\\theta) = \\frac{1}{2} \\sum_{j=1}^n \\theta_j^2 = \\frac{1}{2}  \\theta^{\\rm T}\\theta.$$\n",
    "\n",
    "\n",
    "*Lasso* regularization adopts $\\ell_1$ regularising term:\n",
    "\n",
    "$$ R(\\theta) =\\sum_{j=1}^n \\left\\vert \\theta_j \\right\\vert .$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "*Elastic net* regularization provides a mix of Tikhonov and Lasso regularization, controlled by mix ratio $r$:\n",
    "\n",
    "$$ R(\\theta) =  r\\sum_{j=1}^n \\left\\vert \\theta_j \\right\\vert + \\frac{1-r}{2} \\sum_{j=1}^n \\theta_j^2.$$\n",
    "\n",
    "- For $r=0$, corresponds to Tikhonov regularization.\n",
    "- For $r=1$, corresponds to Lasso regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropout is a very popular and effective regularlisation technique developed by [Geoff Hinton in 2012](http://www.jmlr.org/papers/volume15/srivastava14a.old/srivastava14a.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Dropout involves simply dropping each neuron for a given training set with probability $p$.\n",
    "\n",
    "<!-- <img src=\"https://raw.githubusercontent.com/astro-informatics/course_mlbd_images/master/Lecture13_Images/dropout.png\" style=\"height: 350px;\"/> -->\n",
    "\n",
    "![](https://raw.githubusercontent.com/astro-informatics/course_mlbd_images/master/Lecture13_Images/dropout.png)\n",
    "\n",
    "[Credit: Geron]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Dropout encourages each neuron to be as effective as possible individually and not to rely heavily on a few nearby neurons but to consider all input neurons carefully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The probability $p$ is called the *dropout rate* (typically $p \\sim 0.5$).\n",
    "\n",
    "After training the neurons don't get dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The number of inputs of active neurons is lower when dropout is applied during training, than when the network is applied during testing.  \n",
    "\n",
    "For example, if $p=0.5$, on average there are half as many input neurons during training than when testing.  During testing each neuron will get an input signal (approximately) twice as large as during training.\n",
    "\n",
    "It is important to account for this difference.\n",
    "\n",
    "To compensate, after training each neurons input weights are multiplied by the keep probability $1-p$ before applying the network to test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data augmentation can be applied both as a regularization technique and to increase the volume of the training set.\n",
    "\n",
    "Essentially, new training instances are created from the original training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For example, for images, data augmentation can be performed by rotating, shifting, scaling, flipping, changing the contrast, ..., of the original images in the training data-set.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/astro-informatics/course_mlbd_images/master/Lecture13_Images/data_augmentation.png\" style=\"height: 500px;\"/>\n",
    "\n",
    "[Credit: Geron]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Appropriate data augmentation strategies depend on the type of data under consideration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Typically training instances are generated on the fly to avoid additional storage requirements.  \n",
    "\n",
    "Tensor Flow has built in functionality for many transformations for image data, making data augmentation for image data straightforward."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
